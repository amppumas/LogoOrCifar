from os.path import exists, join
from os import remove
from keras.optimizers import rmsprop
from keras.preprocessing.image import ImageDataGenerator
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Conv2D, MaxPooling2D
from .load_functions import load_and_create_dataset, create_dirs
from pickle import load, dump
from logocifar.constants import \
    format_model_name, PROCESSED_DATASET_PATH, MDL_FILE_EXT, DATASET_EXISTS, SAVING_DATASET, \
    error_message, NOT_ENOUGH_MEMORY, MODEL_PATH, MODEL_TRAINED, SAVED_TRAINED, trained_model


class LogoOrCifar:
    def __init__(self, train_sz, cifar_len, lld_len):

        self.cifar_len = cifar_len
        self.lld_len = lld_len
        self.model_name = format_model_name(cifar_len, lld_len)

        images, labels = self.load_data()

        self.x_train = images[:train_sz]
        self.y_train = to_categorical(labels[:train_sz], 2)
        test_sz = len(labels) - train_sz
        self.x_test = images[:-test_sz]
        self.y_test = to_categorical(labels[:-test_sz], 2)

        self.model = None
        self.model_path = ''

    def load_data(self):
        dataset_path = PROCESSED_DATASET_PATH + self.model_name + MDL_FILE_EXT

        if exists(dataset_path):
            print(DATASET_EXISTS)
            with open(dataset_path, 'rb') as f:
                images, labels = load(f, encoding='bytes')
        else:
            create_dirs(PROCESSED_DATASET_PATH)
            images, labels = load_and_create_dataset(
                self.cifar_len,
                self.lld_len
            )
            if self.lld_len != 0:
                print(SAVING_DATASET, dataset_path)
                with open(dataset_path, 'wb') as f:
                    try:
                        dump((images, labels), f)
                    except (MemoryError, OverflowError):
                        remove(dataset_path)
                        error_message(NOT_ENOUGH_MEMORY)

        return images, labels

    def define_model(self, conv=2, flat=512):
        model = Sequential()
        model.add(Conv2D(32, (3, 3),
                         padding='same',
                         input_shape=self.x_train.shape[1:]))
        model.add(Activation('relu'))
        model.add(Conv2D(32, (3, 3)))
        model.add(Activation('relu'))
        model.add(MaxPooling2D(pool_size=(2, 2)))
        model.add(Dropout(0.25))

        model.add(Conv2D(64, (3, 3), padding='same'))
        model.add(Activation('relu'))
        model.add(Conv2D(64, (3, 3)))
        model.add(Activation('relu'))
        model.add(MaxPooling2D(pool_size=(2, 2)))
        model.add(Dropout(0.25))

        if conv == 3:
            model.add(Conv2D(96, (3, 3), padding='same'))
            model.add(Activation('relu'))
            model.add(Conv2D(96, (3, 3)))
            model.add(Activation('relu'))
            model.add(Dropout(0.25))

        model.add(Flatten())
        model.add(Dense(flat))
        model.add(Activation('relu'))
        # model.add(Dropout(0.5))
        model.add(Dense(2))
        model.add(Activation('softmax'))
        self.model = model
        self.model_name += trained_model(flat, conv)
        # Save model and weights
        self.model_path = join(create_dirs(MODEL_PATH), self.model_name)
        if not exists(self.model_path):
            return self.initialize_model()
        else:
            print(MODEL_TRAINED.format(self.model_name))
            return False

    def initialize_model(self):

        # initiate RMSprop optimizer
        opt = rmsprop(lr=0.0001, decay=1e-6)

        # Let's train the model using RMSprop
        self.model.compile(loss='categorical_crossentropy',
                           optimizer=opt,
                           metrics=['accuracy'])

        self.x_train /= 255
        self.x_test /= 255

        return True

    def fit_to_data(self, batch_size=32, epochs=1):
        # This will do preprocessing and realtime data augmentation:
        datagen = ImageDataGenerator(
            featurewise_center=True,  # set input mean to 0
            samplewise_center=False,  # set each sample mean to 0
            featurewise_std_normalization=True,  # divide inputs by stdeviation
            samplewise_std_normalization=False,  # divide each input by its std
            zca_whitening=False,  # apply ZCA whitening,
            rotation_range=0,  # randomly rotate images (degrees, 0 to 180)
            width_shift_range=0,  # randomly shift images horizontally
            height_shift_range=0,  # randomly shift images vertically
            horizontal_flip=False,  # randomly flip images
            vertical_flip=False)  # randomly flip images

        datagen.fit(self.x_train)

        # Fit the model on the batches generated by datagen.flow().
        self.model.fit_generator(datagen.flow(self.x_train, self.y_train,
                                              batch_size=batch_size),
                                 epochs=epochs,
                                 validation_data=(self.x_test, self.y_test),
                                 workers=4,
                                 verbose=1)

        self.model.save(self.model_path)
        print(SAVED_TRAINED, self.model_path)
